{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, CSVLogger\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, ReLU, Softmax, Dropout, Conv2D, MaxPool2D, Flatten, Reshape\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_shuffle(images, tile_size=None):\n",
    "    if tile_size is None:\n",
    "        tile_size = np.random.choice((2, 4, 7, 14), size=1)[0]\n",
    "    n_tiles = 28//tile_size # in 1-D\n",
    "    \n",
    "    n_im = images.shape[0]\n",
    "    \n",
    "    images = np.reshape(images, (n_im, tile_size, n_tiles, tile_size, n_tiles), order='F')\n",
    "    images = np.transpose(images, (0, 2, 4, 3, 1))\n",
    "    images = np.reshape(images, (n_im, n_tiles*n_tiles, tile_size, tile_size), order='F')\n",
    "    \n",
    "    images = images[:, np.random.permutation(n_tiles*n_tiles)]\n",
    "    \n",
    "    images = np.reshape(images, (n_im, n_tiles, n_tiles, tile_size, tile_size), order='F')\n",
    "    images = np.transpose(images, (0, 3, 2, 4, 1))\n",
    "    images = np.reshape(images, (n_im, n_tiles*tile_size, n_tiles*tile_size), order='F')\n",
    "    images = np.reshape(images, (n_im, 784))\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_generator(dir_mnist, batch_size=16, dataset='train', random_order=True,\n",
    "                    null_types=None, p_null_class=1/11, tile_size=None):\n",
    "    # dataset: May be 'train' or 'test'\n",
    "    # null_types: A string of character, with each character indicating a type of\n",
    "    #             image that will be used for the null class:\n",
    "    #                 'u' - uniform noise\n",
    "    #                 's' - tile-shuffled MNIST images\n",
    "    #                 'm' - mixed: two MNIST images (of different classes) averaged/mixed together\n",
    "    #             For example: 'um' indicates that null samples will include both uniform noise\n",
    "    #             samples and mixed sampled.\n",
    "            \n",
    "    from mnist import MNIST\n",
    "    mndata = MNIST(dir_mnist)\n",
    "\n",
    "    if dataset=='train':\n",
    "        images, labels = mndata.load_training()\n",
    "    elif dataset=='test':\n",
    "        images, labels = mndata.load_testing()\n",
    "    else:\n",
    "        raise Exception(\"MNIST dataset must be 'train' or 'test'\")\n",
    "\n",
    "    images = np.array(images).astype(np.float32) / 255\n",
    "    labels = np.array(labels).astype(np.float32)\n",
    "    n_samples = labels.shape[0]\n",
    "    \n",
    "    global idx_pointer\n",
    "    idx_pointer = 0\n",
    "    def get_next_sample_indices(n_wanted, random_order=random_order):\n",
    "        global idx_pointer\n",
    "        if random_order:\n",
    "            ix_mnist = np.random.choice(n_samples, size=n_wanted, replace=False)\n",
    "        else:\n",
    "            ix_mnist = np.arange(idx_pointer, idx_pointer+n_wanted, dtype=np.int)\n",
    "            ix_mnist = ix_mnist % n_samples\n",
    "            idx_pointer += n_wanted\n",
    "            if idx_pointer >= n_samples:\n",
    "                idx_pointer = idx_pointer % n_samples    \n",
    "        return ix_mnist\n",
    "        \n",
    "    while True:\n",
    "        # Determine how many samples to get of each type/class\n",
    "        if null_types is None or null_types=='':\n",
    "            n_mnist = batch_size\n",
    "            n_uniform = 0\n",
    "            n_shuffled = 0\n",
    "            n_mixed = 0            \n",
    "        else:\n",
    "            # Warning: not checking to make sure null_types string is legitimate\n",
    "            prob_type = np.array(['u' in null_types, 's' in null_types, 'm' in null_types])\n",
    "            prob_type = prob_type / np.sum(prob_type)\n",
    "            \n",
    "            n_nulls = np.sum(np.random.uniform(size=(batch_size)) < p_null_class)            \n",
    "            n_mnist = batch_size - n_nulls\n",
    "\n",
    "            iid_type = np.random.choice([0, 1, 2], size=n_nulls, replace=True, p=prob_type)\n",
    "            n_uniform = np.sum(iid_type==0)\n",
    "            n_shuffled = np.sum(iid_type==1)\n",
    "            n_mixed = np.sum(iid_type==2)\n",
    "\n",
    "        # Randomly select mnist samples.\n",
    "        ix_mnist = get_next_sample_indices(n_mnist)\n",
    "        labels_batch = labels[ix_mnist]\n",
    "        images_batch = images[ix_mnist]\n",
    "\n",
    "        # Generate the uniform noise null images.\n",
    "        labels_other = np.full((n_uniform), 10, dtype=np.float32)\n",
    "        images_other = np.random.uniform(0, high=1, size=(n_uniform, 784)).astype(np.float32)\n",
    "        labels_batch = np.concatenate((labels_batch, labels_other))\n",
    "        images_batch = np.concatenate((images_batch, images_other))\n",
    "        \n",
    "        # Generate the shuffled null images.\n",
    "        # All images of batch have pixels shuffled in same order.\n",
    "        labels_other = np.full((n_shuffled), 10, dtype=np.float32)\n",
    "        ix_mnist = get_next_sample_indices(n_shuffled)\n",
    "        images_other = tile_shuffle(images[ix_mnist], tile_size=tile_size)\n",
    "        labels_batch = np.concatenate((labels_batch, labels_other))\n",
    "        images_batch = np.concatenate((images_batch, images_other))\n",
    "\n",
    "        # Generate the mixed null images.\n",
    "        labels_other = np.full((n_mixed), 10, dtype=np.float32)\n",
    "        images_other = np.empty((0, 784), dtype=np.float32)\n",
    "        cnt = 0\n",
    "        while cnt < n_mixed:\n",
    "            got_one = False\n",
    "            while not got_one:\n",
    "                ix_mnist = get_next_sample_indices(2)\n",
    "                if labels[ix_mnist[0]] != labels[ix_mnist[1]]:\n",
    "                    got_one = True\n",
    "                    im = ((images[ix_mnist[0]] + images[ix_mnist[1]]) / 2).astype(np.float32)\n",
    "                    images_other = np.concatenate((images_other, np.expand_dims(im, axis=0)))\n",
    "            cnt += 1\n",
    "        labels_batch = np.concatenate((labels_batch, labels_other))\n",
    "        images_batch = np.concatenate((images_batch, images_other))\n",
    "        \n",
    "        # yield images_batch, labels_batch\n",
    "        yield images_batch, labels_batch, [None]\n",
    "        # Added [None] to get rid of mystery error messsage in TF 2.1:\n",
    "        #    sample_weight modes were coerced from ... to ['...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramp_generator(batch_size=16, null_types=None, p_null_class=1/3):\n",
    "    # null_types: A string of character, with each character indicating a type of\n",
    "    #             image that will be used for the null class:\n",
    "    #                 'u' - uniform noise\n",
    "    #                 's' - shuffled samples\n",
    "    #             For example: 'us' indicates that null samples will include both uniform noise\n",
    "    #             samples and shuffled sampled.\n",
    "\n",
    "    proto_ramps = np.array([[0.666, 0.333], [0.333, 0.666]])\n",
    "    \n",
    "    def create_ramps(n_samples):\n",
    "        ramps = np.zeros((n_samples, 3), dtype=np.float32)\n",
    "        \n",
    "        n0 = np.sum(np.random.uniform(size=(n_samples)) < 0.5)\n",
    "        n1 = n_samples - n0\n",
    "                \n",
    "        # Probably some faster/smarter way of doing this\n",
    "        shifts = np.random.choice(2, size=(n0))\n",
    "        for i in range(n0):\n",
    "            ramps[i, shifts[i]:shifts[i]+2] = proto_ramps[0]\n",
    "        shifts = np.random.choice(2, size=(n1))\n",
    "        for i in range(n1):\n",
    "            ramps[i+n0, shifts[i]:shifts[i]+2] = proto_ramps[1]\n",
    "        \n",
    "        # Add some noise\n",
    "        ramps += np.random.uniform(-0.05, high=0.05, size=(n_samples, 3)).astype(np.float32)\n",
    "        ramps = np.clip(ramps, 0, 1)\n",
    "        \n",
    "        labels = np.zeros((n_samples,1))\n",
    "        labels[n0:,0] = 1\n",
    "        \n",
    "        return ramps, labels\n",
    "    \n",
    "    while True:\n",
    "        # Determine how many samples to get of each type/class\n",
    "        if null_types is None or null_types=='':\n",
    "            n_ramps = batch_size\n",
    "            n_uniform = 0\n",
    "            n_shuffled = 0\n",
    "        else:\n",
    "            # Warning: not checking to make sure null_types string is legitimate\n",
    "            prob_type = np.array(['u' in null_types, 's' in null_types])\n",
    "            prob_type = prob_type / np.sum(prob_type)\n",
    "            \n",
    "            n_nulls = np.sum(np.random.uniform(size=(batch_size)) < p_null_class)            \n",
    "            n_ramps = batch_size - n_nulls\n",
    "\n",
    "            iid_type = np.random.choice([0, 1], size=n_nulls, replace=True, p=prob_type)\n",
    "            n_uniform = np.sum(iid_type==0)\n",
    "            n_shuffled = np.sum(iid_type==1)\n",
    "\n",
    "        # Get true samples.\n",
    "        images_batch, labels_batch = create_ramps(n_ramps)\n",
    "\n",
    "        # Generate the uniform noise null images.\n",
    "        labels_other = np.full((n_uniform, 1), 2, dtype=np.float32)\n",
    "        images_other = np.random.uniform(0, high=1, size=(n_uniform, 3)).astype(np.float32)\n",
    "        labels_batch = np.concatenate((labels_batch, labels_other))\n",
    "        images_batch = np.concatenate((images_batch, images_other))\n",
    "        \n",
    "        # Generate the shuffled null images.\n",
    "        # All images of batch have pixels shuffled in same order.\n",
    "        labels_other = np.full((n_shuffled, 1), 2, dtype=np.float32)\n",
    "        images_other, _ = create_ramps(n_shuffled)\n",
    "        ix = np.random.permutation(3)\n",
    "        images_other = images_other[:,ix]\n",
    "        labels_batch = np.concatenate((labels_batch, labels_other))\n",
    "        images_batch = np.concatenate((images_batch, images_other))\n",
    "        \n",
    "        yield images_batch, labels_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tensorflow2",
   "language": "python",
   "name": "env_tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
